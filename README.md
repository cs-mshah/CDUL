# CDUL
Implementation to CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification

## Setup

Create a `.env` file at the root of the `CDUL` repository to store environment variables. Set the `DATASETS_ROOT` (for downloading and preparing the datasets) and `PROJECT_ROOT` (the path to this directory). It is recommended to create an account on [weights and biases](https://wandb.ai/) for logging experiments.  

Example:  

```shell
PROJECT_ROOT='<path to this repository>/CDUL'
DATASETS_ROOT='<path to your datasets folder>/datasets'
WANDB_API_KEY=<your wandb api key>
WANDB_ENTITY=<wandb entity (username)>
WANDB_PROJECT=CDUL
```

Also export the above environment variables by adding them to any of `.bashrc`/`.zshrc`/by [conda env activation](https://guillaume-martin.github.io/saving-environment-variables-in-conda.html).  

Creating a conda environment:

```shell
conda create -n cdul python=3.10.12
conda activate cdul
pip install -r requirements.txt
```

## Project Structure

```shell
.
│
├── configs                   <- Hydra configs
│   ├── data                     <- Data configs
│   ├── experiment               <- Experiment configs
│   ├── hydra                    <- Hydra configs
│   ├── logger                   <- Logger configs
│   ├── model                    <- Model configs
│   ├── paths                    <- Project paths configs
│   │
│   └── config.yaml            <- Main config for running
│
│
├── clip_cache             <- Cache generated on the PASCAL VOC 2012 dataset for 'global' vectors and 'aggregate' vectors
├── logs                   <- Experiment Logs generated by hydra (generated when conducting experiments)
├── wandb                  <- Offline Logs generated by wandb (generated when conducting experiments)
│
│
├── src                    <- Source code
│   ├── data                     <- Data files
│	│   │
│   │	├── data.py              <- Contains generic classes for manipulating data: CLIPCache, TileCropDataset
│	│   └── voc.py               <- Contains functions and classes specific to the PASCAL VOC 2012 dataset
│   │
│   ├── models                   <- Model files
│   ├── utils                    <- Utility files
│   │
│   ├── clip_cache.py            <- Run the cache generation for 'global', 'aggregate' vectors
│   ├── evaluate.py              <- Evaluate the mAP for a specific pseudo label initialization (i.e evaluate the generated cache)
│   └── train.py                 <- Train the classifier using the generated cache
│
│
├── .env                      <- File for storing environment variables
├── .project-root             <- File for inferring the position of project root directory (do not delete)
├── Makefile                  <- Makefile with commands like `make train` or `make test`
├── requirements.txt          <- File for installing python dependencies
└── README.md                 <- README file specifying project instructions
```

## Running
For convenience, a `Makefile` has been provided to execute underlying commands for various tasks. Run `make help` for all available commands (this assumes that you have make installed). Kindly check [Hydra](https://github.com/facebookresearch/hydra) and [Lightning-Hydra-Template](https://github.com/ashleve/lightning-hydra-template) to understand more about using the configs.

### Verifying Claims of the Original Paper

We need to verify the following central claims:  

1. The effectiveness of the aggregation of global and local alignments generated by CLIP in forming
pseudo labels for training an unsupervised classifier.  
2. The effectiveness of the gradient-alignment training method, which recursively updates the network
parameters and the pseudo labels, to update the quality of the initial pseudo labels.  

We currently try to verify the claims on the PASCAL VOC 2012 dataset.  
For downloading the PASCAL VOC dataset to the `DATASETS_ROOT` folder run `make voc2012`.

### Claim 1

To generate pseudo label vector caches for the global and aggregate alignment vectors using various snippet sizes run the following commands:
```
# cache global similarity vectors
make clip_cache

# cache aggregate vectors with snippet size 16 x 16
make clip_cache16

# cache aggregate vectors with snippet size 32 x 32
make clip_cache32

# cache aggregate vectors with snippet size 64 x 64
make clip_cache64
```

A `clip_cache` folder will get created under the dataset folder. For the PASCAL VOC 2012 dataset, the filetree looks like:

```shell
VOC2012
│
├── Annotations
├── clip_cache - this contains cached vectors in different hierarchies as per the config values
├── ImageSets
├── JPEGImages
├── SegmentationClass
└── SegmentationObject
```
For evaluating the `clip_cache` provided in this repository, copy the `clip_cache` folder to the above location in the downloaded PASCAL VOC 2012 dataset.

For evaluating the quality (**mAP**) of the initial pseudo labels run:

```
# Note: for evaluating, you must have the clip_cache created using either the above commands or the provided cache.

# to evaluate the pseudo labels initialzed only using the global similarity vectors
make evaluate

# evaluate final pseudo labels (average of global and aggregate) using snippet size 16 x 16
make evaluate16

# evaluate final pseudo labels using snippet size 32 x 32
make evaluate32

# evaluate final pseudo labels using snippet size 64 x 64
make evaluate64
```

### Claim 2

For training the classifier network on the global similarity vectors as the initial pseudo labels, run:
`make train`.  
To train using final pseudo label vectors, change the `target_transform` field in the appropriate yaml config file under `configs/experiment` of an experiment and then run `python src/train.py experiment=<snippet_size>_patch`. More details can be seen in the comments of various config files.  
The pseudo label update frequency has been set to 10. Change this in the config files accordingly.

To disable logging using weights and biases, prefix any command with `WANDB_MODE=disabled`.

## TODO

- [ ] Run experiments on other datasets.  
- [ ] Generate a cache for a snippet size of 3 x 3.  
